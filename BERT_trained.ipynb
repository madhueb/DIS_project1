{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import sklearn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TripletMarginWithDistanceLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available:  True\n",
      "GPU:  Quadro RTX 4000\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "print(\"Cuda is available: \", is_cuda)\n",
    "print(\"GPU: \", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv('./Data/dev.csv')\n",
    "test = pd.read_csv('./Data/test.csv')\n",
    "train = pd.read_csv('./Data/train.csv')\n",
    "sample_submission = pd.read_csv('./Data/sample_submission.csv')\n",
    "with open(\"./Data/corpus.json\", \"r\") as f:\n",
    "    documents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return a @ b / (torch.norm(a) * torch.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m triplet_loss \u001b[38;5;241m=\u001b[39m TripletMarginWithDistanceLoss(distance_function\u001b[38;5;241m=\u001b[39mcosine_sim)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# Nombre d'époques\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dev)):\n\u001b[1;32m      7\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Réinitialiser les gradients\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "triplet_loss = TripletMarginWithDistanceLoss(distance_function=cosine_sim)\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm(range(num_epochs)):  # Nombre d'époques\n",
    "    for i in range(len(dev)):\n",
    "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
    "        docs_pos = [doc[\"text\"] for doc in documents if doc[\"docid\"] == dev['positive_docs'].iloc[i]]\n",
    "        docs_neg = [doc[\"text\"] for doc in documents if doc[\"docid\"] in dev['negative_docs'].iloc[i]][:1]\n",
    "        query = dev['query'].iloc[i]\n",
    "\n",
    "        inputs_docs_pos = tokenizer(docs_pos, return_tensors=\"pt\", padding=True, truncation=True,max_length=512).to(device)\n",
    "        inputs_docs_neg = tokenizer(docs_neg, return_tensors=\"pt\", padding=True, truncation=True,max_length=512).to(device)\n",
    "        inputs_query = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True,max_length=512).to(device)\n",
    "\n",
    "        outputs_docs_pos = model(**inputs_docs_pos)  # Passer les documents positifs dans le modèle\n",
    "        outputs_docs_neg = model(**inputs_docs_neg)\n",
    "        output_query = model(**inputs_query)\n",
    "\n",
    "        pos_doc_embedding = outputs_docs_pos.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "        neg_doc_embedding = outputs_docs_neg.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "        query_embedding = output_query.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "\n",
    "        loss = triplet_loss(query_embedding, pos_doc_embedding, neg_doc_embedding)     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
