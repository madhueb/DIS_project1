{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from src.dataloaders.vec_dataset import VecDataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from config.config import CONFIG",
   "id": "f1b38013e1c89d17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.models.embedder import Embedder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model'], use_fast=CONFIG['tokenizer_use_fast'])\n",
    "embedder = AutoModel.from_pretrained(CONFIG['model']).to(CONFIG['device'])"
   ],
   "id": "e872faf79c82105f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_df = pd.read_csv(CONFIG['train_path'])\n",
    "dev_df = pd.read_csv(CONFIG['dev_path'])"
   ],
   "id": "954ce1fc49056472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.models.utils import query_embedding\n",
    "\n",
    "train_df['query_embed'] = train_df['query'].apply(lambda x: query_embedding(x, embedder, tokenizer, CONFIG))\n",
    "dev_df['query_embed'] = dev_df['query'].apply(lambda x: query_embedding(x, embedder, tokenizer, CONFIG))"
   ],
   "id": "2919212b2784abd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upsample_data(df):\n",
    "    # Upsample the data to balance across languages\n",
    "    lang_counts = df['lang'].value_counts()\n",
    "    max_count = lang_counts.max()\n",
    "    upsampled_dfs = []\n",
    "    for lang in lang_counts.index:\n",
    "        lang_df = df[df['lang'] == lang]\n",
    "        upsampled_df = lang_df.sample(max_count - lang_counts[lang], replace=True)\n",
    "        upsampled_dfs.append(pd.concat([lang_df, upsampled_df]))\n",
    "    return pd.concat(upsampled_dfs)"
   ],
   "id": "16e3a3870201d130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_df = upsample_data(train_df)",
   "id": "626f89da1abb17e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save query embeddings\n",
    "train_df.to_csv(CONFIG['train_emb_path'], index=False)\n",
    "dev_df.to_csv(CONFIG['dev_emb_path'], index=False)"
   ],
   "id": "1091b6653ab83957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load query embeddings\n",
    "train_df = pd.read_csv(CONFIG['train_emb_path'])\n",
    "dev_df = pd.read_csv(CONFIG['dev_emb_path'])"
   ],
   "id": "4454d328e44cb8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "# load document embeddings\n",
    "with open(CONFIG['doc_embeds_path'], 'rb') as f:\n",
    "    doc_embeds = pickle.load(f)"
   ],
   "id": "93bdb38294a18a2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.dataloaders.utils import get_train_val_dataloaders\n",
    "\n",
    "train_dl, val_dl = get_train_val_dataloaders(CONFIG, train_df, dev_df, doc_embeds)"
   ],
   "id": "f5730e2684fa56e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "accelerator = Accelerator(gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'])",
   "id": "ee2e8112199d40f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.training.trainner import Trainer\n",
    "from src.models.dpr import DPRModel\n",
    "\n",
    "embed_size = embedder.config.hidden_size \n",
    "model = DPRModel(embed_size).to(CONFIG['device'])\n",
    "trainer = Trainer(model, (train_dl, val_dl), CONFIG, accelerator)"
   ],
   "id": "249c2fa12689e277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()",
   "id": "7fc27544f198549d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "losses_df = pd.DataFrame({'epoch':list(range(1, CONFIG['epochs'] + 1)),\n",
    "                          'train_loss':trainer.train_losses, \n",
    "                          'val_loss': trainer.val_losses\n",
    "                         })\n",
    "losses_df.to_csv(CONFIG['losses_path'], index=False)"
   ],
   "id": "39984c81f035fdae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(trainer.train_losses, color='red')\n",
    "plt.plot(trainer.val_losses, color='orange')\n",
    "plt.title('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ],
   "id": "e6a08613a958bf86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.models.encoder import Encoder\n",
    "\n",
    "embed_size = embedder.config.hidden_size\n",
    "doc_encoder = Encoder(embed_size).to(CONFIG['device'])\n",
    "doc_encoder.load_state_dict(torch.load(f\"{CONFIG['load_path']}/doc_encoder.pth\"))"
   ],
   "id": "516d736bc71c1e3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.dataloaders.vec_dataset import VecDataset\n",
    "\n",
    "docids = []\n",
    "langs = []\n",
    "vecs = []\n",
    "for docid, embed_dict in doc_embeds.items():\n",
    "    for embed in embed_dict['embeds']:\n",
    "        docids.append(docid)\n",
    "        langs.append(embed_dict['lang'])\n",
    "        vecs.append(embed)\n",
    "    \n",
    "vec_ds = VecDataset(docids, langs, vecs)"
   ],
   "id": "10924616d4168230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "vec_dataloader = torch.utils.data.DataLoader(vec_ds, batch_size=256, collate_fn=vec_ds.collate_fn, shuffle=False, num_workers=4)\n",
    "\n",
    "doc_encodes = []\n",
    "doc_ids = []\n",
    "doc_langs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(vec_dataloader, desc=\"Encoding documents\"):\n",
    "        doc_ids.extend(batch['doc_id'])\n",
    "        doc_langs.extend(batch['lang'])\n",
    "        doc_encodes.extend([doc_encode for doc_encode in doc_encoder(batch['vec'].to(CONFIG['device'])).cpu().numpy()])\n",
    "        "
   ],
   "id": "b1f3217f64437ba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "encode_dict = {}\n",
    "\n",
    "for docid, lang, encode_chunk in tqdm(zip(doc_ids, doc_langs, doc_encodes), desc=\"Creating encode dictionary\"):\n",
    "    if docid not in encode_dict:\n",
    "        encode_dict[docid] = {'lang': lang, 'encodes': []}\n",
    "    encode_dict[docid]['encodes'].append(encode_chunk)\n"
   ],
   "id": "ae7133837cb3869b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "with open(CONFIG['doc_encodes_path'], 'wb') as f:\n",
    "    pickle.dump(encode_dict, f)"
   ],
   "id": "512457e2ee1677b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
