{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from config.config import CONFIG",
   "id": "f1b38013e1c89d17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.models.embedder import Embedder\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model'], use_fast=CONFIG['tokenizer_use_fast'])\n",
    "embedder = Embedder(CONFIG).to(CONFIG['device'])"
   ],
   "id": "e872faf79c82105f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_df = pd.read_csv(CONFIG['train_path'])\n",
    "dev_df = pd.read_csv(CONFIG['dev_path'])"
   ],
   "id": "954ce1fc49056472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.models.utils import query_embedding\n",
    "\n",
    "train_df['query_embed'] = train_df['query'].apply(lambda x: query_embedding(x, embedder, tokenizer, CONFIG))\n",
    "dev_df['query_embed'] = dev_df['query'].apply(lambda x: query_embedding(x, embedder, tokenizer, CONFIG))"
   ],
   "id": "2919212b2784abd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def upsample_data(df):\n",
    "    # Upsample the data to balance across languages\n",
    "    lang_counts = df['lang'].value_counts()\n",
    "    max_count = lang_counts.max()\n",
    "    upsampled_dfs = []\n",
    "    for lang in lang_counts.index:\n",
    "        lang_df = df[df['lang'] == lang]\n",
    "        upsampled_df = lang_df.sample(max_count - lang_counts[lang], replace=True)\n",
    "        upsampled_dfs.append(pd.concat([lang_df, upsampled_df]))\n",
    "    return pd.concat(upsampled_dfs)"
   ],
   "id": "16e3a3870201d130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_df = upsample_data(train_df)",
   "id": "626f89da1abb17e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save query embeddings\n",
    "train_df.to_csv(CONFIG['train_emb_path'], index=False)\n",
    "dev_df.to_csv(CONFIG['dev_emb_path'], index=False)"
   ],
   "id": "1091b6653ab83957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load query embeddings\n",
    "train_df = pd.read_csv(CONFIG['train_emb_path'])\n",
    "dev_df = pd.read_csv(CONFIG['dev_emb_path'])"
   ],
   "id": "4454d328e44cb8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "# load document embeddings\n",
    "with open(CONFIG['doc_embeds_path'], 'rb') as f:\n",
    "    doc_embeds = pickle.load(f)"
   ],
   "id": "93bdb38294a18a2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.dataloaders.utils import get_train_val_dataloaders\n",
    "\n",
    "train_dl, val_dl = get_train_val_dataloaders(CONFIG, train_df, dev_df, doc_embeds)"
   ],
   "id": "f5730e2684fa56e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "accelerator = Accelerator(gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'])",
   "id": "ee2e8112199d40f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.training.trainner import Trainer\n",
    "from src.models.dpr import DPRModel\n",
    "\n",
    "embed_size = embedder.model.get_output_dim()\n",
    "model = DPRModel(embed_size).to(CONFIG['device'])\n",
    "trainer = Trainer(model, (train_dl, val_dl), CONFIG, accelerator)"
   ],
   "id": "249c2fa12689e277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()",
   "id": "7fc27544f198549d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "losses_df = pd.DataFrame({'epoch':list(range(1, CONFIG['epochs'] + 1)),\n",
    "                          'train_loss':trainer.train_losses, \n",
    "                          'val_loss': trainer.val_losses\n",
    "                         })\n",
    "losses_df.to_csv(CONFIG['losses_path'], index=False)"
   ],
   "id": "39984c81f035fdae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(trainer.train_losses, color='red')\n",
    "plt.plot(trainer.val_losses, color='orange')\n",
    "plt.title('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')"
   ],
   "id": "e6a08613a958bf86"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
